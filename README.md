üìä Data-Driven Stock Analysis 

Project Overview
This project focuses on analyzing and visualizing the performance of Nifty 50 stocks over a one-year period using a data-driven approach. The solution processes raw stock market data, calculates key financial metrics, stores data in a relational database, and presents insights through Python analysis, an interactive Streamlit dashboard, MySQL SQL queries, and Power BI dashboards.
The project is designed for beginners and follows industry-standard workflows used in real-world data analytics projects.
________________________________________
Business Objectives
‚Ä¢	Identify Top 10 Gainers and Top 10 Losers based on yearly returns
‚Ä¢	Provide a market overview using KPIs
‚Ä¢	Analyze sector-wise performance
‚Ä¢	Understand stock price correlation
‚Ä¢	Track monthly gainers and losers
‚Ä¢	Support investment decision-making using data insights
‚Ä¢	Validate analytical results using SQL queries
________________________________________
Tools & Technologies
1) Languages & Libraries
‚Ä¢	Python 3.11
‚Ä¢	Pandas
‚Ä¢	NumPy
‚Ä¢	Matplotlib
‚Ä¢	PyYAML
‚Ä¢	SQLAlchemy
2) Visualization Tools
‚Ä¢	Streamlit (Interactive Dashboard)
‚Ä¢	Power BI Desktop

3) Databases
‚Ä¢	MySQL (Database)
________________________________________
Project Architecture
Stock_Analysis_Project/
‚îÇ
‚îú‚îÄ‚îÄ data_yaml/                 
‚îú‚îÄ‚îÄ data_csv/                  
‚îú‚îÄ‚îÄ data_reference/          
‚îú‚îÄ‚îÄ data_powerbi/
‚îú‚îÄ‚îÄ          
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ yaml_to_csv.py        
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py            
‚îÇ   ‚îú‚îÄ‚îÄ create_powerbi_csv.py  
‚îÇ
‚îú‚îÄ‚îÄ load_data_to_mysql.py      
‚îú‚îÄ‚îÄ dashboard.py               
‚îú‚îÄ‚îÄ README.md                  
‚îî‚îÄ‚îÄ requirements.txt           
________________________________________
Project Workflow (End-to-End)
Step 1: Data Collection
‚Ä¢	Input data provided in YAML format
‚Ä¢	Organized into month-wise folders
‚Ä¢	Each YAML file contains daily stock data
________________________________________
Step 2: Data Extraction & Cleaning
‚Ä¢	YAML files are parsed using Python
‚Ä¢	Data is cleaned and standardized
‚Ä¢	Output: 50 CSV files, one per stock
Script used:
python scripts/yaml_to_csv.py
________________________________________
Step 3: Data Analysis (Python)
Using Pandas, the following metrics are calculated:
‚Ä¢	Daily Returns
‚Ä¢	Yearly Returns
‚Ä¢	Volatility (Standard Deviation of daily returns)
‚Ä¢	Cumulative Returns
‚Ä¢	Monthly Returns
Script used:
python scripts/analysis.py
________________________________________
Step 4: Database Storage (MySQL)
‚Ä¢	Cleaned stock data is loaded into MySQL using Pandas and SQLAlchemy
‚Ä¢	Enables SQL-based validation for top 10 gainers & losers of analytical results
‚Ä¢	Ensures consistency across Python, Streamlit, and Power BI
Script used:
python load_data_to_mysql.py
________________________________________
Step 5: Streamlit Dashboard
An interactive dashboard built using Streamlit to visualize:
‚Ä¢	Stock price trends
‚Ä¢	Top gainers & losers
‚Ä¢	Sector-wise performance
‚Ä¢	Monthly analysis
Run the dashboard:
streamlit run dashboard.py
________________________________________

Step 6: Power BI Data Preparation
‚Ä¢	All stock CSVs are combined into a single dataset
‚Ä¢	Sector mapping is merged
‚Ä¢	Output: Power BI‚Äìready CSV file
Script used:
python scripts/create_powerbi_csv.py
________________________________________
Step 7: Power BI Dashboard
Power BI is used to build:
‚Ä¢	KPI cards (Market overview)
‚Ä¢	Top gainers & losers
‚Ä¢	Sector-wise performance
‚Ä¢	Correlation heatmap
‚Ä¢	Monthly gainers & losers
________________________________________
Key Visualizations
‚Ä¢	Stock Price Trend (Month-wise)
‚Ä¢	Top 10 Gainers (Yearly)
‚Ä¢	Top 10 Losers (Yearly)
‚Ä¢	Sector-wise Average Return
‚Ä¢	Correlation Heatmap
‚Ä¢	Top 5 Gainers & Losers (Monthly)
________________________________________
Project Deliverables
‚Ä¢	Cleaned CSV datasets
‚Ä¢	Python scripts for ETL & analysis
‚Ä¢	Streamlit interactive dashboard
‚Ä¢	Power BI dashboard
‚Ä¢	Well-documented GitHub repository
________________________________________

How to Run This Project
1.Install dependencies
pip install -r requirements.txt
2.Convert YAML to CSV
python scripts/yaml_to_csv.py
3.Run analysis
python scripts/analysis.py
4. Load data into MySQL
python load_data_to_mysql.py
5.Launch Streamlit app
streamlit run dashboard.py
6.Open Power BI
‚Ä¢	Load data_powerbi/all_stocks.csv
‚Ä¢	Build visuals using Power BI Desktop
________________________________________
Coding Standards Followed
‚Ä¢	Modular scripts
‚Ä¢	Meaningful variable names
‚Ä¢	Beginner-friendly logic
‚Ä¢	Inline comments for clarity
________________________________________
Future Enhancements
‚Ä¢	Live stock data integration (API)
‚Ä¢	Automated database refresh
‚Ä¢	Deployment on Streamlit Cloud
‚Ä¢	Advanced risk metrics (Sharpe Ratio, Beta)
________________________________________




Demo Video Link
https://www.linkedin.com/posts/nisha-savariar_datascience-dataanalytics-python-activity-7407864354995576833-snPD?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFmmQMIB0iVcomJx8dDIIc6t9Wu0MBIP9wE
________________________________________
üë©‚Äçüíª Author
Nisha
Data Science Project ‚Äì Stock Market Analysis
‚≠ê If you find this project useful, feel free to star the repository!



